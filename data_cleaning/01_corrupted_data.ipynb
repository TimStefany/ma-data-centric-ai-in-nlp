{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dealing with corrupted values\n",
    "\n",
    "## descriptions that are too short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4246 entries, 0 to 4245\n",
      "Data columns (total 4 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   startup_ID                   4246 non-null   int64 \n",
      " 1   description_startupdetector  592 non-null    object\n",
      " 2   startup_description          4112 non-null   object\n",
      " 3   industry                     4246 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 132.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/00_baseline/raw_data.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge descriptions as in prepare_dataset_csv.py\n",
    "df['description'] = df['description_startupdetector'].fillna(df['startup_description'])\n",
    "# sort for description length an look at the shortest ones\n",
    "df['len_description'] = df['description'].apply(lambda x: len(x))\n",
    "df_sort = df.sort_values('len_description', ascending=False)\n",
    "df_sort.to_csv('../data/01_corrupted/further_data/full_sorted_length.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from looking at the csv file we chose 47 as threshold length for descriptions. Below this threshold most descriptions seem to be mainly a chain of Keywords and not a proper description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3905 entries, 0 to 4245\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   startup_ID                   3905 non-null   int64 \n",
      " 1   description_startupdetector  590 non-null    object\n",
      " 2   startup_description          3772 non-null   object\n",
      " 3   industry                     3905 non-null   object\n",
      " 4   description                  3905 non-null   object\n",
      " 5   len_description              3905 non-null   int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 213.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# remove all rows with descriptions shorter than 47\n",
    "df.drop(df[df['len_description'] < 47].index, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## removing missing values\n",
    "\n",
    "although there are no NaN values in the description column we found descriptions like \"unknown\" or \"no information\" during data exploration. The goal is to find all synonyms for missing descriptions and remove them from the dataset. We will not remove incorrect descriptions in this step since they are considered \"corrupted data\"\n",
    "\n",
    "Most of them are already handeled by the length threshold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## found \"missing\" values\n",
    "\n",
    "found through string length:\n",
    "- unknown\n",
    "- unknow\n",
    "- Unknown\n",
    "- no infos\n",
    "- no startup\n",
    "- Placeholder\n",
    "- no information\n",
    "- no informations\n",
    "\n",
    "found throguh duplicate descriptions:\n",
    "- GROW by Pioniergarage Team 2020 - No description available.\n",
    "\n",
    "the one from the duplicate descriptions is the only one longer than 47. This is why we will only remove rows with this description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 9 \"missing\" values\n"
     ]
    }
   ],
   "source": [
    "missing_value = 'GROW by Pioniergarage Team 2020 - No description available.'\n",
    "\n",
    "old_len = len(df)\n",
    "# drop all rows with these descriptions\n",
    "df = df.drop(df[df['description'] == missing_value].index)\n",
    "\n",
    "print(f'removed {old_len - len(df)} \"missing\" values')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further errors detected through manual checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "man_error = pd.read_csv('../data/01_corrupted/further_data/data_errors_manual_check.csv')\n",
    "# get startup_IDs of Data Error entries\n",
    "man_error['Data Error'] = man_error['Data Error'].fillna(False)\n",
    "man_error = man_error.loc[man_error['Data Error']]\n",
    "man_err_ids = man_error['startup_ID'].tolist()\n",
    "len(man_err_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "droped 9 corrupted rows\n"
     ]
    }
   ],
   "source": [
    "old_len = len(df)\n",
    "# drop rows if startup_ID is in list\n",
    "df = df.drop(df[df['startup_ID'].isin(man_err_ids)].index)\n",
    "print(f'droped {old_len - len(df)} corrupted rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new dataframe withoug corrupted rows\n",
    "df = df.drop(columns=['description', 'len_description'])\n",
    "df.to_csv('../data/01_corrupted/raw_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_win",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

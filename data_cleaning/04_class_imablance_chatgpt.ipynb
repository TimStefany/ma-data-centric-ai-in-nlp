{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05a2cf6e",
   "metadata": {},
   "source": [
    "### Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e489e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT library\n",
    "import openai\n",
    "import tiktoken\n",
    "# data libraries\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# other libraries\n",
    "import os\n",
    "from tqdm.notebook import tqdm # progress bar\n",
    "import configparser\n",
    "import pprint\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn', disables a warning for later\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('api_key.ini')\n",
    "openai.api_key = config.get('openai', 'tim_key')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0e6ad19",
   "metadata": {},
   "source": [
    "### Data and Model loading\n",
    "\n",
    "we want to work with the best possible input descriptions for this. Therefore we take the raw data of the 'corrupted' dataset and replace the industry labels with the cleaned ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c13d863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3969 entries, 0 to 3968\n",
      "Data columns (total 5 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   startup_ID                   3969 non-null   int64 \n",
      " 1   description_startupdetector  607 non-null    object\n",
      " 2   startup_description          3832 non-null   object\n",
      " 3   industry                     3969 non-null   object\n",
      " 4   description                  3969 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 155.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# loading in data\n",
    "df_corr = pd.read_csv(\"../data/corrupted/raw_data.csv\")\n",
    "df_ind = pd.read_csv(\"../data/label_correction/raw_data.csv\")\n",
    "\n",
    "# replacing industry labels in corrupted with ones from label_correction\n",
    "df_corr = df_corr.drop(columns=['industry'])\n",
    "df = df_corr.merge(df_ind[['startup_ID', 'industry']], 'left', 'startup_ID')\n",
    "\n",
    "# merge descriptions\n",
    "df['description'] = df['description_startupdetector'].fillna(df['startup_description'])\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea5fc4b5",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac6ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate batch lists from description column, containing 10 descriptions each\n",
    "def generate_batches_for_industry(df, industry: str, batchsize: int):\n",
    "    # get list of descriptions\n",
    "    desc_lst = df.loc[df['industry'] == industry, 'description'].tolist()\n",
    "\n",
    "    # batch size\n",
    "    n = batchsize\n",
    "\n",
    "    # building batches\n",
    "    batches = [desc_lst[i * n:(i + 1) * n] for i in range((len(desc_lst) + n - 1) // n )]\n",
    "\n",
    "    # print(len(batches))\n",
    "    # print(len(batches[0]))\n",
    "\n",
    "    return batches\n",
    "\n",
    "# count how many tokens are in one request\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5dfa63bc",
   "metadata": {},
   "source": [
    "### Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "385c3fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we define the Sustainability and GreenTech industry by these keywords:\n",
      "\n",
      "\"\"\"Sustainability, Recycling, AgrarTech, Sharing economy, Water management, CleanTech, Forest economy\"\"\"\n",
      "\n",
      "Generate 4 examples for startup descriptions in the Sustainability and GreenTech industry. Descriptions should be in the same domain as the examples provided below. Examples can not be in the mobility, energy, supply chain and construction sector. The output should contain the descriptions in csv format.\n",
      "\n",
      "Examples:\n",
      "Example 1: he customer borrows the shopping bag instead of buying it. He just pays a small fee and uses our product with full service and on demand. The customer can return the bag when it is no longer needed or dirty. The joeybags stay in the system and are used over and over again.\n",
      "##\n",
      "Example 2: The idea of Urban Hochbeet germinated in the summer of 2020- in the midst of the Corona pandemic. The project is a complete package that offers a raised bed, fresh plants, suitable soil, fertilizer and care instructions.\n",
      "##\n"
     ]
    }
   ],
   "source": [
    "# generating input function\n",
    "def generate_input(descriptions: list, industry: str, keywords: list, excluded_ind: str) -> str:\n",
    "  \"\"\"generates a text prompt for chatgpt from descriptions, target industry, keywords defining the industry and sectors to exclude\"\"\"\n",
    "  \n",
    "  def _add_examples(examples: list):\n",
    "    out = 'Examples:'\n",
    "    i = 1\n",
    "    for example in examples:\n",
    "      out += f'\\nExample {i}: {example}\\n##'\n",
    "      i += 1\n",
    "    return out\n",
    "  \n",
    "  input = f'''we define the {industry} industry by these keywords:\n",
    "\n",
    "\"\"\"{\", \".join(keywords)}\"\"\"\n",
    "\n",
    "Generate {len(descriptions * 2)} examples for startup descriptions in the {industry} industry. Descriptions should be in the same domain as the examples provided below. Examples can not be in the {excluded_ind} sector. The output should contain the descriptions in csv format.\n",
    "\n",
    "{_add_examples(descriptions)}'''\n",
    "  \n",
    "  return input\n",
    "\n",
    "\n",
    "descriptions = ['he customer borrows the shopping bag instead of buying it. He just pays a small fee and uses our product with full service and on demand. The customer can return the bag when it is no longer needed or dirty. The joeybags stay in the system and are used over and over again.',\n",
    "                'The idea of Urban Hochbeet germinated in the summer of 2020- in the midst of the Corona pandemic. The project is a complete package that offers a raised bed, fresh plants, suitable soil, fertilizer and care instructions.']\n",
    "industry = 'Sustainability and GreenTech'\n",
    "keywords = ['Sustainability', 'Recycling', 'AgrarTech', 'Sharing economy', 'Water management', 'CleanTech', 'Forest economy']\n",
    "excluded_ind = 'mobility, energy, supply chain and construction'\n",
    "\n",
    "\n",
    "# completion = openai.ChatCompletion.create(\n",
    "#   model=\"gpt-3.5-turbo\",\n",
    "#   messages=[\n",
    "#     {\"role\": \"user\", \"content\": generate_input(descriptions, industry, keywords, excluded_ind)}\n",
    "#   ]\n",
    "# )\n",
    "print(generate_input(descriptions, industry, keywords, excluded_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4a88b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "619\n",
      "657\n",
      "664\n",
      "721\n",
      "402\n"
     ]
    }
   ],
   "source": [
    "# test number of tokens for each batch in AR & VR\n",
    "batches = generate_batches_for_industry(df, 'AR & VR', 10)\n",
    "\n",
    "for batch in batches:\n",
    "    industry = 'Sustainability & GreenTech'\n",
    "    keywords = ['Sustainability', 'Recycling', 'AgrarTech', 'Sharing economy', 'Water management', 'CleanTech', 'Forest economy']\n",
    "    excluded_ind = 'health, medicine, production, education, retail, mobility, construction, supply chain and finance'\n",
    "    \n",
    "    promt = generate_input(descriptions= batch, industry='AR & VR', keywords=keywords, excluded_ind=excluded_ind)\n",
    "    \n",
    "    print(num_tokens_from_string(promt, \"gpt-3.5-turbo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7916466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937835ba30fb4b08988e150a7aab71da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "industry = 'Mobility & Transportation'\n",
    "\n",
    "batches = generate_batches_for_industry(df, industry, 5)\n",
    "\n",
    "keywords = ['Automotive', 'Smart Mobility', 'Aviation', 'Autonomous driving', 'Micromobility', 'Charging station', 'SpaceTech', 'Rail transport', 'Mobility / Transport']\n",
    "excluded_ind = 'supplychain, energy, education, retail, logistics and construction'\n",
    "\n",
    "responses = []\n",
    "\n",
    "for batch in tqdm(batches):\n",
    "    for test in range(1,5):\n",
    "        try:\n",
    "            promt = generate_input(batch, industry, keywords, excluded_ind)\n",
    "            response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                                    messages=[{\"role\": \"user\", \"content\": promt}],\n",
    "                                                    temperature=1.25,\n",
    "                                                    max_tokens=1024,\n",
    "                                                    top_p=1,\n",
    "                                                    frequency_penalty=0,\n",
    "                                                    presence_penalty=0\n",
    "                                                    )\n",
    "            response_text = response.choices[0].message.content\n",
    "            responses.append(response_text)\n",
    "            break\n",
    "        \n",
    "        except openai.OpenAIError as e:\n",
    "            sleep_dur = 20\n",
    "            print(f\"Error: {e}. Retrying in {sleep_dur} seconds.\")\n",
    "            time.sleep(sleep_dur)\n",
    "            continue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb326ead",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0027a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(f'./generated/{industry}_responses_2.txt','w')\n",
    "for response in responses:\n",
    "\tfile.write(response + \"\\n\")\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('ml_text')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aea880fc0c2751ea23e9e1ed1a83637b11d3bf6b71d39b034214716fbe6fcd3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
